{"cells":[{"cell_type":"markdown","source":["# HackOnData.com\n\n## Exercise #3 - Log Analysis\n\n\n### Week 3 Lab 1:\n\nMake sure you complete the Week 3 Lab 1:\n\nhttps://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2799933550853697/3719583162088724/2202577924924539/latest.html\n\nInclude the public link to the lab solutions:"],"metadata":{}},{"cell_type":"markdown","source":["https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/8122459673715921/364006105196051/2531719484635850/latest.html"],"metadata":{}},{"cell_type":"markdown","source":["## TranQuant Log:\n\nStarting from\n\nhttp://tranquant.com/subscriptions/569c985d-f1f3-42c5-8b81-11b644e42895 \n\nThe following fields are included:\n\n```\n log>\n |-- action: string (nullable = true) | Action\n |-- obj_id: string (nullable = true) | Object Id\n |-- obj_type: string (nullable = true) | Object Type\n |-- timestamp: long (nullable = true) | Time Stamp\n |-- type: string (nullable = true) | Type\n |-- ua: string (nullable = true) | User Agent\n |-- uuid: string (nullable = true) | UUID\n```\n\nExample:\n\n| action | obj_id | obj_type |\ttimestamp |\ttype |\tua |\tuuid |\n| ------------- |:-------------:| -----:|\n|hover |\tAccommodation and Food Services\t| main_category_title |\t1467962138212\t| Event\t| Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36\t| 83e28957-3a80-4d3c-b189-339fe0d66c4b|\n\n\nThe log corresponds to front-end events for TranQuant."],"metadata":{}},{"cell_type":"markdown","source":["### Text parsing\nRead each line of the log file as text. Write a regular expression to parse the first 3 fields (action, obj_id, and obj_type), ignore the remaining fields for now. \n\nHint: Similar to `def parseLogs():` in the Lab"],"metadata":{}},{"cell_type":"code","source":["import json \n\nfileName = \"/mnt/my-hod-data/TQ_web_analytics_de_identified.log\"\n\n# Import full dataset as text file\ndata_raw = sc.textFile(fileName)\n\n# Parse JSON entries in dataset\ndata = data_raw.map(lambda line: json.loads(line))\n\n# Extract relevant fields in dataset\ndata_triplet = data.map(lambda line: (line['action'], line['obj_id'], line['obj_type']))\n\ndata_triplet.count()\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["What are the most popular (top 6) `obj_id`? present the results in a plot."],"metadata":{}},{"cell_type":"code","source":["obj_id_count = (data.map(lambda x: (x['obj_id'], 1))\n                          .reduceByKey(lambda a, b : a + b))\n\nobj_id_count_ordered = obj_id_count.sortBy(lambda x:x[1], ascending=False)\n\nimport pandas as pd\nobj_counted = pd.DataFrame(obj_id_count_ordered.collect(), columns=[\"obj_id\", \"count\"])\nobj_counted[:6]"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Create an RDD with Row objects\ncounts_schema_rdd = sqlContext.createDataFrame(obj_counted)\n\n# Display a plot of the obj_id distribution \ndisplay(counts_schema_rdd)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["As we can see at the plot above, the most poopular obj_id's are about 50% of the whole population."],"metadata":{}},{"cell_type":"markdown","source":["Read the logs using the dataframes API. Example:\n\n`log = sqlContext.read.json(\"/mnt/HackOnData/challenge3/TQ_web_analytics_de_identified.log\")`\n\n`log.printSchema()`"],"metadata":{}},{"cell_type":"code","source":["logDF = sqlContext.read.json(fileName)\n\nlogDF.printSchema() \n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### UA Fields\n\nParse the ua field  (https://en.wikipedia.org/wiki/User_agent) and extract all the subfields"],"metadata":{}},{"cell_type":"code","source":["dataUA = logDF.select('ua')\n\ndataUA.first()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["import re\nfrom pyspark.sql import Row\n\n# A regular expression pattern to extract UA fields \nUSER_AGENT_PATTERN = '^(\\S+) \\(([^(]*)\\) (\\S+) \\(([^(]*)\\) (\\S+) (\\S+)'\n\ndef parseUALogLine(logline):\n    \"\"\" Parse UA log line \n    Args:\n        logline (str): a line of text in the UA Log format\n    Returns:\n        tuple: either a dictionary containing the parts of the UA Fields and 1,\n               or the original invalid log line and 0\n    \"\"\"\n    match = re.search(USER_AGENT_PATTERN, logline)\n    if match is None:\n        return (logline, 0)\n    \n    return (Row(\n        browser_compatibility    = match.group(1),\n        os_ver                   = match.group(2),\n        platform                 = match.group(3),\n        browser_platform_details = match.group(4),\n        enhancement_1            = match.group(5),\n        enhancement_2            = match.group(6)        \n    ))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Convert the timestamp to hour of the day (0-23). Make a histogram."],"metadata":{}},{"cell_type":"code","source":["import datetime\n\ndataTS = logDF.select('timestamp')\n\nhour_of_day = dataTS.map(lambda x: (datetime.datetime.fromtimestamp(int(x[0])/1000).hour,1)).reduceByKey(lambda a,b: a+b)\nhour_of_day = hour_of_day.sortByKey()\n\nhd_counted = pd.DataFrame(hour_of_day.collect(), columns=[\"Hour\", \"Count\"])\n\ncounts_schema_hd = sqlContext.createDataFrame(hd_counted)\ndisplay(counts_schema_hd)\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["What we can see on the histogram:\n\n* Morning is a period of the lowest load on the server\n* The maximum load is observed during non-business hours"],"metadata":{}},{"cell_type":"markdown","source":["Repeat the same exercise for the the top 3 browsers, do you find any interesting results?"],"metadata":{}},{"cell_type":"code","source":["wb = (dataUA.map(lambda log: (log[0], 1)).reduceByKey(lambda a, b : a + b))\n\nwb_counted = pd.DataFrame(wb.collect(), columns=[\"UA\", \"Count\"])\n\nwb_count_ordered = wb_counted.sort(['Count'], ascending=[0])\n\n# Top3\nwb_count_ordered[:3]\n"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["counts_schema_wb = sqlContext.createDataFrame(wb_count_ordered)\ndisplay(counts_schema_wb)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["As we can see from the chart above, Top 3 browser configurations are more than 60% of all the observed."],"metadata":{}},{"cell_type":"code","source":["top3wb = wb_count_ordered[:3]\ntop3wb.iat[0,0], top3wb.iat[1,0], top3wb.iat[2,0]"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["And we can notice that all top3 configurations are based on Chrome."],"metadata":{}},{"cell_type":"markdown","source":["## flight solo....\n\nWe want to encourange creativity, we want you to tell a story supported by data.\n\nWhat other slice and dice can you perform to extract useful insights?\n\nWhat recommendations do you have for TranQuant based on the log analysis you performed? please show your intermadiate steps, use graphs, be yourself and express your point of view."],"metadata":{}},{"cell_type":"markdown","source":["The Day of the Week pattern may be as important as the Hour of the Day."],"metadata":{}},{"cell_type":"code","source":["dow = dataTS.map(lambda x: (datetime.date.fromtimestamp(int(x[0])/1000).isoweekday(), 1)).reduceByKey(lambda a,b: a+b)\n\ndow = dow.sortByKey()\n\ndw_counted = pd.DataFrame(dow.collect(), columns=[\"Day of Week\", \"Count\"])\n\ncounts_schema_wd = sqlContext.createDataFrame(dw_counted)\ndisplay(counts_schema_wd)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["This chart is the histogram of events depending on the day of the week, from Monday (1) to Sunday (7). The histogram shows that the load on the server in average is higher from Monday to Thursday (when it is maximal), than in the rest of the week. \n\nCombining these results with the Hour of the Day histogram, it is possible to suggest that the load on the server reached extremal values on Thursday nights for the observed period."],"metadata":{}}],"metadata":{"name":"Exercise 3","notebookId":2549719220288433},"nbformat":4,"nbformat_minor":0}
